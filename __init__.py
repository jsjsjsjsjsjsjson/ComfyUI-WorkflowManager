# __init__.py
"""
ComfyUI Workflow Manager Plugin
å®Œæ•´çš„å·¥ä½œæµæ–‡ä»¶ç®¡ç†å™¨ - æ”¯æŒæ–‡ä»¶å¤¹åˆ›å»ºã€é‡å‘½åã€ç§»åŠ¨ã€å¤åˆ¶ã€åˆ é™¤ç­‰å®Œæ•´æ–‡ä»¶æ“ä½œ
"""

import os
import json
import shutil
import logging
from aiohttp import web
import folder_paths
from server import PromptServer

WEB_DIRECTORY = "./js"
NODE_CLASS_MAPPINGS = {}
NODE_DISPLAY_NAME_MAPPINGS = {}

__version__ = "1.0.0"
__author__ = "ComfyUI Community"
__description__ = "Complete workflow file manager with full filesystem operations"

def get_workflows_directory():
    """è·å–ç”¨æˆ·å·¥ä½œæµç›®å½•è·¯å¾„"""
    user_dir = folder_paths.get_user_directory()
    return os.path.join(user_dir, "default", "workflows")

def ensure_workflows_directory():
    """ç¡®ä¿å·¥ä½œæµç›®å½•å­˜åœ¨"""
    workflows_dir = get_workflows_directory()
    os.makedirs(workflows_dir, exist_ok=True)
    return workflows_dir

def get_config_path():
    """è·å–é…ç½®æ–‡ä»¶è·¯å¾„"""
    plugin_dir = os.path.dirname(__file__)
    return os.path.join(plugin_dir, '.workflow_manager_config.json')

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = get_config_path()
    default_config = {
        'viewMode': 'list',  # é»˜è®¤åˆ—è¡¨è§†å›¾
        'sortBy': 'name',
        'sortOrder': 'asc'
    }
    
    try:
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                # åˆå¹¶é»˜è®¤é…ç½®ï¼Œç¡®ä¿æ‰€æœ‰é…ç½®é¡¹éƒ½å­˜åœ¨
                return {**default_config, **config}
        else:
            return default_config
    except Exception as e:
        logging.warning(f"Failed to load config: {e}")
        return default_config

def save_config(config):
    """ä¿å­˜é…ç½®æ–‡ä»¶"""
    try:
        config_path = get_config_path()
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        logging.error(f"Failed to save config: {e}")
        return False

def is_safe_path(base_path, target_path):
    """æ£€æŸ¥è·¯å¾„æ˜¯å¦å®‰å…¨ï¼Œé˜²æ­¢ç›®å½•éå†æ”»å‡»"""
    base_path = os.path.abspath(base_path)
    target_path = os.path.abspath(target_path)
    return target_path.startswith(base_path)

@PromptServer.instance.routes.post("/workflow-manager/save-view-mode")
async def save_view_mode(request):
    """ä¿å­˜è§†å›¾æ¨¡å¼"""
    try:
        data = await request.json()
        view_mode = data.get('viewMode', 'list')
        
        # åŠ è½½ç°æœ‰é…ç½®
        config = load_config()
        config['viewMode'] = view_mode
        
        success = save_config(config)
        
        if success:
            return web.json_response({"success": True})
        else:
            return web.json_response({"success": False, "error": "ä¿å­˜è§†å›¾æ¨¡å¼å¤±è´¥"}, status=500)
            
    except Exception as e:
        logging.error(f"Failed to save view mode: {e}")
        return web.json_response({"success": False, "error": str(e)}, status=500)

@PromptServer.instance.routes.get("/workflow-manager/browse")
async def browse_directory(request):
    """æµè§ˆç›®å½•å†…å®¹"""
    try:
        path = request.query.get('path', '').strip()
        workflows_dir = ensure_workflows_directory()
        
        if path:
            target_dir = os.path.join(workflows_dir, path)
        else:
            target_dir = workflows_dir
            
        if not is_safe_path(workflows_dir, target_dir):
            return web.json_response({"success": False, "error": "æ— æ•ˆçš„è·¯å¾„"}, status=400)
            
        if not os.path.exists(target_dir):
            return web.json_response({"success": False, "error": "ç›®å½•ä¸å­˜åœ¨"}, status=404)
        
        items = []
        
        # è·å–ç›®å½•å†…å®¹
        for item_name in sorted(os.listdir(target_dir)):
            item_path = os.path.join(target_dir, item_name)
            relative_path = os.path.relpath(item_path, workflows_dir).replace('\\', '/')
            
            if os.path.isdir(item_path):
                # ç»Ÿè®¡æ–‡ä»¶å¤¹ä¸­çš„å·¥ä½œæµæ•°é‡
                workflow_count = 0
                try:
                    for file in os.listdir(item_path):
                        if file.endswith('.json'):
                            workflow_count += 1
                except:
                    workflow_count = 0
                    
                items.append({
                    "name": item_name,
                    "type": "directory",
                    "path": relative_path,
                    "size": 0,
                    "modified": os.path.getmtime(item_path),
                    "workflow_count": workflow_count
                })
            elif item_name.endswith('.json'):
                # å·¥ä½œæµæ–‡ä»¶
                file_size = os.path.getsize(item_path)
                items.append({
                    "name": item_name,
                    "type": "workflow",
                    "path": relative_path,
                    "size": file_size,
                    "modified": os.path.getmtime(item_path)
                })
        
        return web.json_response({
            "success": True,
            "current_path": path,
            "items": items,
            "config": load_config()  # æ·»åŠ é…ç½®ä¿¡æ¯
        })
        
    except Exception as e:
        logging.error(f"Failed to browse directory: {e}")
        return web.json_response({"success": False, "error": str(e)}, status=500)

@PromptServer.instance.routes.post("/workflow-manager/create-folder")
async def create_folder(request):
    """åˆ›å»ºæ–‡ä»¶å¤¹"""
    try:
        data = await request.json()
        folder_name = data.get('name', '').strip()
        parent_path = data.get('parent_path', '').strip()
        
        if not folder_name:
            return web.json_response({"success": False, "error": "æ–‡ä»¶å¤¹åç§°ä¸èƒ½ä¸ºç©º"}, status=400)
        
        # æ£€æŸ¥æ–‡ä»¶å¤¹åç§°æ˜¯å¦åˆæ³•
        if any(char in folder_name for char in r'<>:"/\|?*'):
            return web.json_response({"success": False, "error": "æ–‡ä»¶å¤¹åç§°åŒ…å«éæ³•å­—ç¬¦"}, status=400)
        
        workflows_dir = ensure_workflows_directory()
        
        if parent_path:
            target_dir = os.path.join(workflows_dir, parent_path, folder_name)
        else:
            target_dir = os.path.join(workflows_dir, folder_name)
        
        if not is_safe_path(workflows_dir, target_dir):
            return web.json_response({"success": False, "error": "æ— æ•ˆçš„è·¯å¾„"}, status=400)
        
        if os.path.exists(target_dir):
            return web.json_response({"success": False, "error": "æ–‡ä»¶å¤¹å·²å­˜åœ¨"}, status=409)
        
        os.makedirs(target_dir, exist_ok=True)
        logging.info(f"Folder created: {target_dir}")
        
        return web.json_response({"success": True, "path": os.path.relpath(target_dir, workflows_dir).replace('\\', '/')})
        
    except Exception as e:
        logging.error(f"Failed to create folder: {e}")
        return web.json_response({"success": False, "error": str(e)}, status=500)

@PromptServer.instance.routes.post("/workflow-manager/rename")
async def rename_item(request):
    """é‡å‘½åæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹"""
    try:
        data = await request.json()
        old_path = data.get('old_path', '').strip()
        new_name = data.get('new_name', '').strip()
        sync_preview = data.get('sync_preview', True)  # é»˜è®¤åŒæ­¥é‡å‘½åé¢„è§ˆå›¾
        
        if not old_path or not new_name:
            return web.json_response({"success": False, "error": "è·¯å¾„å’Œæ–°åç§°ä¸èƒ½ä¸ºç©º"}, status=400)
        
        # æ£€æŸ¥æ–°åç§°æ˜¯å¦åˆæ³•
        if any(char in new_name for char in r'<>:"/\|?*'):
            return web.json_response({"success": False, "error": "åç§°åŒ…å«éæ³•å­—ç¬¦"}, status=400)
        
        workflows_dir = ensure_workflows_directory()
        old_full_path = os.path.join(workflows_dir, old_path)
        
        if not is_safe_path(workflows_dir, old_full_path):
            return web.json_response({"success": False, "error": "æ— æ•ˆçš„è·¯å¾„"}, status=400)
        
        if not os.path.exists(old_full_path):
            return web.json_response({"success": False, "error": "æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ä¸å­˜åœ¨"}, status=404)
        
        # æ„å»ºæ–°è·¯å¾„
        parent_dir = os.path.dirname(old_full_path)
        new_full_path = os.path.join(parent_dir, new_name)
        
        if os.path.exists(new_full_path):
            return web.json_response({"success": False, "error": "ç›®æ ‡åç§°å·²å­˜åœ¨"}, status=409)
        
        # å¦‚æœæ˜¯JSONå·¥ä½œæµæ–‡ä»¶ï¼ŒæŸ¥æ‰¾å¹¶å‡†å¤‡é‡å‘½åé¢„è§ˆå›¾æ–‡ä»¶
        preview_files_to_rename = []
        if sync_preview and not os.path.isdir(old_full_path) and old_path.lower().endswith('.json'):
            preview_extensions = ['.webp', '.png', '.jpg', '.jpeg', '.gif', '.bmp']
            old_base_path = os.path.splitext(old_full_path)[0]
            
            # ç¡®ä¿æ–°åç§°åŒ…å«.jsonæ‰©å±•å
            if not new_name.lower().endswith('.json'):
                new_name_with_ext = new_name + '.json'
                new_full_path = os.path.join(parent_dir, new_name_with_ext)
            else:
                new_name_with_ext = new_name
                
            new_base_path = os.path.splitext(new_full_path)[0]
            
            for ext in preview_extensions:
                old_preview_path = old_base_path + ext
                if os.path.exists(old_preview_path):
                    new_preview_path = new_base_path + ext
                    preview_files_to_rename.append((old_preview_path, new_preview_path))
        
        # é‡å‘½åä¸»æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹
        os.rename(old_full_path, new_full_path)
        logging.info(f"Renamed: {old_full_path} -> {new_full_path}")
        
        # é‡å‘½åå¯¹åº”çš„é¢„è§ˆå›¾æ–‡ä»¶
        for old_preview, new_preview in preview_files_to_rename:
            try:
                os.rename(old_preview, new_preview)
                logging.info(f"Renamed preview: {old_preview} -> {new_preview}")
            except Exception as e:
                logging.warning(f"Failed to rename preview {old_preview}: {e}")
        
        return web.json_response({
            "success": True, 
            "new_path": os.path.relpath(new_full_path, workflows_dir).replace('\\', '/')
        })
        
    except Exception as e:
        logging.error(f"Failed to rename: {e}")
        return web.json_response({"success": False, "error": str(e)}, status=500)

@PromptServer.instance.routes.post("/workflow-manager/delete")
async def delete_item(request):
    """åˆ é™¤æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹"""
    try:
        data = await request.json()
        item_path = data.get('path', '').strip()
        sync_preview = data.get('sync_preview', True)  # é»˜è®¤åŒæ­¥åˆ é™¤é¢„è§ˆå›¾
        
        if not item_path:
            return web.json_response({"success": False, "error": "è·¯å¾„ä¸èƒ½ä¸ºç©º"}, status=400)
        
        workflows_dir = ensure_workflows_directory()
        full_path = os.path.join(workflows_dir, item_path)
        
        if not is_safe_path(workflows_dir, full_path):
            return web.json_response({"success": False, "error": "æ— æ•ˆçš„è·¯å¾„"}, status=400)
        
        if not os.path.exists(full_path):
            return web.json_response({"success": False, "error": "æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ä¸å­˜åœ¨"}, status=404)
        
        # å¦‚æœæ˜¯JSONå·¥ä½œæµæ–‡ä»¶ï¼Œè®°å½•é¢„è§ˆå›¾è·¯å¾„
        preview_files_to_delete = []
        if sync_preview and not os.path.isdir(full_path) and item_path.lower().endswith('.json'):
            # æŸ¥æ‰¾å¯¹åº”çš„é¢„è§ˆå›¾æ–‡ä»¶
            preview_extensions = ['.webp', '.png', '.jpg', '.jpeg', '.gif', '.bmp']
            base_path = os.path.splitext(full_path)[0]
            
            for ext in preview_extensions:
                preview_path = base_path + ext
                if os.path.exists(preview_path):
                    preview_files_to_delete.append(preview_path)
        
        # åˆ é™¤ä¸»æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹
        if os.path.isdir(full_path):
            shutil.rmtree(full_path)
        else:
            os.remove(full_path)
            
        logging.info(f"Deleted: {full_path}")
        
        # åˆ é™¤å¯¹åº”çš„é¢„è§ˆå›¾æ–‡ä»¶
        for preview_path in preview_files_to_delete:
            try:
                os.remove(preview_path)
                logging.info(f"Deleted preview: {preview_path}")
            except Exception as e:
                logging.warning(f"Failed to delete preview {preview_path}: {e}")
        
        return web.json_response({"success": True})
        
    except Exception as e:
        logging.error(f"Failed to delete: {e}")
        return web.json_response({"success": False, "error": str(e)}, status=500)

@PromptServer.instance.routes.post("/workflow-manager/move")
async def move_item(request):
    """ç§»åŠ¨æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹"""
    try:
        data = await request.json()
        source_path = data.get('source_path', '').strip()
        target_dir = data.get('target_dir', '').strip()
        sync_preview = data.get('sync_preview', True)  # é»˜è®¤åŒæ­¥ç§»åŠ¨é¢„è§ˆå›¾
        
        if not source_path:
            return web.json_response({"success": False, "error": "æºè·¯å¾„ä¸èƒ½ä¸ºç©º"}, status=400)
        
        workflows_dir = ensure_workflows_directory()
        source_full_path = os.path.join(workflows_dir, source_path)
        
        if target_dir:
            target_full_dir = os.path.join(workflows_dir, target_dir)
        else:
            target_full_dir = workflows_dir
        
        if not is_safe_path(workflows_dir, source_full_path) or not is_safe_path(workflows_dir, target_full_dir):
            return web.json_response({"success": False, "error": "æ— æ•ˆçš„è·¯å¾„"}, status=400)
        
        if not os.path.exists(source_full_path):
            return web.json_response({"success": False, "error": "æºæ–‡ä»¶ä¸å­˜åœ¨"}, status=404)
        
        if not os.path.exists(target_full_dir):
            return web.json_response({"success": False, "error": "ç›®æ ‡ç›®å½•ä¸å­˜åœ¨"}, status=404)
        
        source_name = os.path.basename(source_full_path)
        target_full_path = os.path.join(target_full_dir, source_name)
        
        if os.path.exists(target_full_path):
            return web.json_response({"success": False, "error": "ç›®æ ‡ä½ç½®å·²å­˜åœ¨åŒåé¡¹ç›®"}, status=409)
        
        # å¦‚æœæ˜¯JSONå·¥ä½œæµæ–‡ä»¶ï¼ŒæŸ¥æ‰¾å¹¶å‡†å¤‡ç§»åŠ¨é¢„è§ˆå›¾æ–‡ä»¶
        preview_files_to_move = []
        if sync_preview and not os.path.isdir(source_full_path) and source_path.lower().endswith('.json'):
            preview_extensions = ['.webp', '.png', '.jpg', '.jpeg', '.gif', '.bmp']
            source_base_path = os.path.splitext(source_full_path)[0]
            target_base_path = os.path.splitext(target_full_path)[0]
            
            for ext in preview_extensions:
                source_preview_path = source_base_path + ext
                if os.path.exists(source_preview_path):
                    target_preview_path = target_base_path + ext
                    preview_files_to_move.append((source_preview_path, target_preview_path))
        
        # ç§»åŠ¨ä¸»æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹
        shutil.move(source_full_path, target_full_path)
        logging.info(f"Moved: {source_full_path} -> {target_full_path}")
        
        # ç§»åŠ¨å¯¹åº”çš„é¢„è§ˆå›¾æ–‡ä»¶
        for source_preview, target_preview in preview_files_to_move:
            try:
                shutil.move(source_preview, target_preview)
                logging.info(f"Moved preview: {source_preview} -> {target_preview}")
            except Exception as e:
                logging.warning(f"Failed to move preview {source_preview}: {e}")
        
        return web.json_response({
            "success": True,
            "new_path": os.path.relpath(target_full_path, workflows_dir).replace('\\', '/')
        })
        
    except Exception as e:
        logging.error(f"Failed to move: {e}")
        return web.json_response({"success": False, "error": str(e)}, status=500)

@PromptServer.instance.routes.post("/workflow-manager/copy")
async def copy_item(request):
    """å¤åˆ¶æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹"""
    try:
        data = await request.json()
        source_path = data.get('source_path', '').strip()
        target_dir = data.get('target_dir', '').strip()
        sync_preview = data.get('sync_preview', True)  # é»˜è®¤åŒæ­¥å¤åˆ¶é¢„è§ˆå›¾
        
        if not source_path:
            return web.json_response({"success": False, "error": "æºè·¯å¾„ä¸èƒ½ä¸ºç©º"}, status=400)
        
        workflows_dir = ensure_workflows_directory()
        source_full_path = os.path.join(workflows_dir, source_path)
        
        if target_dir:
            target_full_dir = os.path.join(workflows_dir, target_dir)
        else:
            target_full_dir = workflows_dir
        
        if not is_safe_path(workflows_dir, source_full_path) or not is_safe_path(workflows_dir, target_full_dir):
            return web.json_response({"success": False, "error": "æ— æ•ˆçš„è·¯å¾„"}, status=400)
        
        if not os.path.exists(source_full_path):
            return web.json_response({"success": False, "error": "æºæ–‡ä»¶ä¸å­˜åœ¨"}, status=404)
        
        if not os.path.exists(target_full_dir):
            return web.json_response({"success": False, "error": "ç›®æ ‡ç›®å½•ä¸å­˜åœ¨"}, status=404)
        
        source_name = os.path.basename(source_full_path)
        target_full_path = os.path.join(target_full_dir, source_name)
        
        # å¦‚æœç›®æ ‡å·²å­˜åœ¨ï¼Œè‡ªåŠ¨é‡å‘½å
        counter = 1
        base_name, ext = os.path.splitext(source_name)
        original_target_full_path = target_full_path
        while os.path.exists(target_full_path):
            if ext:
                new_name = f"{base_name}_copy{counter}{ext}"
            else:
                new_name = f"{base_name}_copy{counter}"
            target_full_path = os.path.join(target_full_dir, new_name)
            counter += 1
        
        # å¦‚æœæ˜¯JSONå·¥ä½œæµæ–‡ä»¶ï¼ŒæŸ¥æ‰¾å¹¶å‡†å¤‡å¤åˆ¶é¢„è§ˆå›¾æ–‡ä»¶
        preview_files_to_copy = []
        if sync_preview and not os.path.isdir(source_full_path) and source_path.lower().endswith('.json'):
            preview_extensions = ['.webp', '.png', '.jpg', '.jpeg', '.gif', '.bmp']
            source_base_path = os.path.splitext(source_full_path)[0]
            target_base_path = os.path.splitext(target_full_path)[0]
            
            for ext_preview in preview_extensions:
                source_preview_path = source_base_path + ext_preview
                if os.path.exists(source_preview_path):
                    target_preview_path = target_base_path + ext_preview
                    preview_files_to_copy.append((source_preview_path, target_preview_path))
        
        # å¤åˆ¶ä¸»æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹
        if os.path.isdir(source_full_path):
            shutil.copytree(source_full_path, target_full_path)
        else:
            shutil.copy(source_full_path, target_full_path)  # æ”¹ä¸ºcopyï¼Œä¸ä¿ç•™å…ƒæ•°æ®
            
        logging.info(f"Copied: {source_full_path} -> {target_full_path}")
        
        # å¤åˆ¶å¯¹åº”çš„é¢„è§ˆå›¾æ–‡ä»¶
        for source_preview, target_preview in preview_files_to_copy:
            try:
                shutil.copy(source_preview, target_preview)
                logging.info(f"Copied preview: {source_preview} -> {target_preview}")
            except Exception as e:
                logging.warning(f"Failed to copy preview {source_preview}: {e}")
        
        return web.json_response({
            "success": True,
            "new_path": os.path.relpath(target_full_path, workflows_dir).replace('\\', '/')
        })
        
    except Exception as e:
        logging.error(f"Failed to copy: {e}")
        return web.json_response({"success": False, "error": str(e)}, status=500)

@PromptServer.instance.routes.get("/workflow-manager/read-workflow")
async def read_workflow(request):
    """è¯»å–å·¥ä½œæµæ–‡ä»¶å†…å®¹"""
    try:
        workflow_path = request.query.get('path', '').strip()
        
        if not workflow_path:
            return web.json_response({"success": False, "error": "å·¥ä½œæµè·¯å¾„ä¸èƒ½ä¸ºç©º"}, status=400)
        
        workflows_dir = ensure_workflows_directory()
        full_path = os.path.join(workflows_dir, workflow_path)
        
        if not is_safe_path(workflows_dir, full_path):
            return web.json_response({"success": False, "error": "æ— æ•ˆçš„è·¯å¾„"}, status=400)
        
        if not os.path.exists(full_path):
            return web.json_response({"success": False, "error": "å·¥ä½œæµæ–‡ä»¶ä¸å­˜åœ¨"}, status=404)
        
        with open(full_path, 'r', encoding='utf-8') as f:
            workflow_data = json.load(f)
        
        return web.json_response({
            "success": True,
            "workflow": workflow_data
        })
        
    except Exception as e:
        logging.error(f"Failed to read workflow: {e}")
        return web.json_response({"success": False, "error": str(e)}, status=500)

@PromptServer.instance.routes.get("/workflow-manager/preview")
async def get_workflow_preview(request):
    """è·å–å·¥ä½œæµé¢„è§ˆå›¾"""
    try:
        path = request.query.get('path', '').strip()
        if not path:
            return web.Response(status=400, text='Path is required')
        
        workflows_dir = ensure_workflows_directory()
        
        # æ„å»ºé¢„è§ˆå›¾è·¯å¾„ï¼ˆå°†.jsonæ›¿æ¢ä¸º.webpï¼‰
        preview_path = os.path.join(workflows_dir, path.replace('.json', '.webp'))
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists(preview_path):
            # è¯»å–webpæ–‡ä»¶
            with open(preview_path, 'rb') as f:
                content = f.read()
            
            # è¿”å›webpå›¾ç‰‡ï¼Œè®¾ç½®ç¼“å­˜å¤´ - ç¦ç”¨ç¼“å­˜
            return web.Response(
                body=content,
                content_type='image/webp',
                headers={
                    'Cache-Control': 'no-cache, no-store, must-revalidate',  # ç¦ç”¨ç¼“å­˜
                    'Pragma': 'no-cache',  # HTTP/1.0å…¼å®¹
                    'Expires': '0',  # ç«‹å³è¿‡æœŸ
                    'Access-Control-Allow-Origin': '*'
                }
            )
        else:
            # é¢„è§ˆå›¾ä¸å­˜åœ¨ï¼Œå°è¯•æŸ¥æ‰¾å…¶ä»–æ ¼å¼
            # å°è¯•å…¶ä»–å›¾ç‰‡æ ¼å¼
            base_path = os.path.splitext(preview_path)[0]
            alternative_formats = ['.png', '.jpg', '.jpeg', '.gif', '.bmp']
            
            for ext in alternative_formats:
                alt_path = base_path + ext
                if os.path.exists(alt_path):
                    # ç¡®å®šæ­£ç¡®çš„content-type
                    content_type_map = {
                        '.png': 'image/png',
                        '.jpg': 'image/jpeg',
                        '.jpeg': 'image/jpeg',
                        '.gif': 'image/gif',
                        '.bmp': 'image/bmp'
                    }
                    
                    content_type = content_type_map.get(ext, 'image/png')
                    
                    with open(alt_path, 'rb') as f:
                        content = f.read()
                    
                    return web.Response(
                        body=content,
                        content_type=content_type,
                        headers={
                            'Cache-Control': 'no-cache, no-store, must-revalidate',  # ç¦ç”¨ç¼“å­˜
                            'Pragma': 'no-cache',  # HTTP/1.0å…¼å®¹
                            'Expires': '0',  # ç«‹å³è¿‡æœŸ
                            'Access-Control-Allow-Origin': '*'
                        }
                    )
            
            # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›404
            return web.Response(status=404, text='Preview not found')
                
    except Exception as e:
        logging.error(f"Failed to serve preview: {e}")
        return web.Response(status=500, text='Internal server error')

@PromptServer.instance.routes.post("/workflow-manager/upload-preview")
async def upload_workflow_preview(request):
    """ä¸Šä¼ å·¥ä½œæµé¢„è§ˆå›¾"""
    try:
        data = await request.post()
        workflow_path = data.get('workflow_path', '').strip()
        preview_file = data.get('preview_file')
        
        if not workflow_path or not preview_file:
            return web.json_response({"success": False, "error": "å‚æ•°ä¸å®Œæ•´"}, status=400)
        
        workflows_dir = ensure_workflows_directory()
        workflow_full_path = os.path.join(workflows_dir, workflow_path)
        
        if not is_safe_path(workflows_dir, workflow_full_path):
            return web.json_response({"success": False, "error": "æ— æ•ˆçš„è·¯å¾„"}, status=400)
        
        if not os.path.exists(workflow_full_path):
            return web.json_response({"success": False, "error": "å·¥ä½œæµæ–‡ä»¶ä¸å­˜åœ¨"}, status=404)
        
        # æ„å»ºé¢„è§ˆå›¾è·¯å¾„ï¼ˆå°†.jsonæ›¿æ¢ä¸º.webpï¼‰
        preview_path = workflow_full_path.replace('.json', '.webp')
        
        # ä¿å­˜é¢„è§ˆå›¾æ–‡ä»¶
        with open(preview_path, 'wb') as f:
            f.write(preview_file.file.read())
        
        logging.info(f"Uploaded preview for: {workflow_path}")
        
        return web.json_response({"success": True})
        
    except Exception as e:
        logging.error(f"Failed to upload preview: {e}")
        return web.json_response({"success": False, "error": str(e)}, status=500)

@PromptServer.instance.routes.post("/workflow-manager/upload-workflow")
async def upload_workflow_file(request):
    """ä¸Šä¼ å·¥ä½œæµæ–‡ä»¶"""
    try:
        reader = await request.multipart()
        workflow_files = []
        target_dir = ''
        create_dirs = False
        
        # è§£æmultipartæ•°æ®
        field = await reader.next()
        while field is not None:
            if field.name == 'target_dir':
                target_dir = (await field.read()).decode('utf-8').strip()
            elif field.name == 'create_dirs':
                create_dirs = (await field.read()).decode('utf-8').strip().lower() == 'true'
            elif field.name == 'workflow_files':
                if hasattr(field, 'filename') and field.filename:
                    # éªŒè¯æ–‡ä»¶æ‰©å±•å
                    if not field.filename.lower().endswith('.json'):
                        return web.json_response({
                            "success": False, 
                            "error": f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {field.filename}ã€‚åªæ”¯æŒ.jsonæ–‡ä»¶"
                        }, status=400)
                    
                    # è¯»å–æ–‡ä»¶å†…å®¹
                    content = await field.read()
                    
                    # éªŒè¯JSONæ ¼å¼
                    try:
                        json.loads(content.decode('utf-8'))
                    except (json.JSONDecodeError, UnicodeDecodeError):
                        return web.json_response({
                            "success": False, 
                            "error": f"æ— æ•ˆçš„JSONæ–‡ä»¶: {field.filename}"
                        }, status=400)
                    
                    workflow_files.append({
                        'filename': field.filename,
                        'content': content
                    })
            
            field = await reader.next()
        
        if not workflow_files:
            return web.json_response({"success": False, "error": "æ²¡æœ‰æœ‰æ•ˆçš„å·¥ä½œæµæ–‡ä»¶"}, status=400)
        
        workflows_dir = ensure_workflows_directory()
        
        # ç¡®å®šç›®æ ‡ç›®å½•
        if target_dir:
            target_full_dir = os.path.join(workflows_dir, target_dir)
        else:
            target_full_dir = workflows_dir
        
        # å®‰å…¨æ£€æŸ¥
        if not is_safe_path(workflows_dir, target_full_dir):
            return web.json_response({"success": False, "error": "æ— æ•ˆçš„ç›®æ ‡è·¯å¾„"}, status=400)
        
        # å¦‚æœå…è®¸åˆ›å»ºç›®å½•ä¸”ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºå®ƒ
        if create_dirs and not os.path.exists(target_full_dir):
            try:
                os.makedirs(target_full_dir, exist_ok=True)
                logging.info(f"Created directory: {target_full_dir}")
            except Exception as e:
                return web.json_response({
                    "success": False, 
                    "error": f"æ— æ³•åˆ›å»ºç›®å½• {target_dir}: {str(e)}"
                }, status=500)
        
        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        if not os.path.exists(target_full_dir):
            return web.json_response({"success": False, "error": "ç›®æ ‡ç›®å½•ä¸å­˜åœ¨"}, status=404)
        
        uploaded_files = []
        errors = []
        
        for file_info in workflow_files:
            filename = file_info['filename']
            content = file_info['content']
            
            # æ„å»ºç›®æ ‡æ–‡ä»¶è·¯å¾„
            target_file_path = os.path.join(target_full_dir, filename)
            
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè‡ªåŠ¨é‡å‘½å
            counter = 1
            base_name, ext = os.path.splitext(filename)
            while os.path.exists(target_file_path):
                new_filename = f"{base_name}_{counter}{ext}"
                target_file_path = os.path.join(target_full_dir, new_filename)
                counter += 1
            
            try:
                # ä¿å­˜æ–‡ä»¶
                with open(target_file_path, 'wb') as f:
                    f.write(content)
                
                final_filename = os.path.basename(target_file_path)
                relative_path = os.path.relpath(target_file_path, workflows_dir).replace('\\', '/')
                
                uploaded_files.append({
                    'filename': final_filename,
                    'path': relative_path
                })
                
                logging.info(f"Uploaded workflow file: {target_file_path}")
                
            except Exception as e:
                errors.append(f"{filename}: {str(e)}")
                logging.error(f"Failed to save workflow file {filename}: {e}")
        
        if uploaded_files:
            message = f"æˆåŠŸä¸Šä¼  {len(uploaded_files)} ä¸ªå·¥ä½œæµæ–‡ä»¶"
            if errors:
                message += f"ï¼Œ{len(errors)} ä¸ªå¤±è´¥"
            
            return web.json_response({
                "success": True,
                "message": message,
                "uploaded_files": uploaded_files,
                "uploaded": len(uploaded_files),
                "errors": errors
            })
        else:
            return web.json_response({
                "success": False, 
                "error": f"æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {'; '.join(errors)}"
            }, status=500)
        
    except Exception as e:
        logging.error(f"Failed to upload workflow files: {e}")
        return web.json_response({"success": False, "error": str(e)}, status=500)

def setup():
    print(f"ğŸš€ ComfyUI Workflow Manager v{__version__} loaded!")
    
    # ç¡®ä¿å·¥ä½œæµç›®å½•å­˜åœ¨
    try:
        workflows_dir = ensure_workflows_directory()
        print(f"   âœ… Workflows directory ready: {workflows_dir}")
    except Exception as e:
        print(f"   âŒ Failed to setup workflows directory: {e}")

setup() 
